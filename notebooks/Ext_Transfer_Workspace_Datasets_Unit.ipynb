{"cells":[{"cell_type":"markdown","source":["#### Workspace Datasets \n","\n","##### Data ingestion strategy:\n","<mark style=\"background: #88D5FF;\">**REPLACE**</mark>\n","\n","##### Related pipeline:\n","\n","**Ext_Load_PBI_Workspace_Datasets_E2E**\n","\n","##### Source:\n","\n","**Files** from FUAM_Ext_Lakehouse folder **bronze_file_location** variable\n","\n","##### Target:\n","\n","**1 Delta table** in FUAM_Ext_Lakehouse \n","- **gold_table_name** variable value\n"],"metadata":{},"id":"e6f3fbdd-e0f2-48ce-82f6-a393d512149e"},{"cell_type":"code","source":["import requests\n","from pyspark.sql.functions import col, lit, udf, explode, to_date, json_tuple, from_json, schema_of_json, get_json_object\n","from pyspark.sql.types import StringType, json\n","from pyspark.sql import SparkSession\n","import json\n","from delta.tables import *\n","import pyspark.sql.functions as f\n","from pyspark.sql.types import *\n","import datetime\n","\n","print(\"Successfully imported all packages for this notebook.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f03f0365-c0b9-433b-a0d1-17bd3c7966bf"},{"cell_type":"code","source":["#\n","# Create the Spark session\n","#\n","app_name = \"TransferWorkspaceDatasets\"\n","\n","# Get the current Spark session\n","spark = SparkSession.builder \\\n","    .appName(app_name) \\\n","    .getOrCreate()\n","\n","spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\",\"true\") # needed for automatic schema evolution in merge\n","\n","print(f\"Spark session {app_name} has been created successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7540f6e3-3f15-4e47-9e8c-9bd9133b692b"},{"cell_type":"code","source":["## Parameters\n","display_data = True\n","\n","## Variables\n","bronze_file_location = f\"Files/raw/workspace_datasets/\"\n","silver_table_name = \"FUAM_Ext_Staging_Lakehouse.workspace_datasets_silver\"\n","gold_table_name = \"workspace_datasets\"\n","gold_table_name_with_prefix = f\"Tables/{gold_table_name}\"\n","\n","print(\"Successfully configured all paramaters for this run.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c69faf2b-0bf5-4b43-8fc9-bb44d210f886"},{"cell_type":"code","source":["# Clean Silver table, if exists\n","if spark.catalog.tableExists(silver_table_name):\n","    del_query = \"DELETE FROM \" + silver_table_name\n","    spark.sql(del_query)\n","    print(f\"Silver table {silver_table_name} has been cleaned successfully.\")\n","else:\n","    print(f\"Silver table {silver_table_name} does not exist.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"61739131-ac46-46e9-bb6b-7d88a66a7382"},{"cell_type":"code","source":["# Get Bronze data\n","bronze_df = spark.read.option(\"multiline\", \"true\").json(bronze_file_location)\n","\n","# Explode json subset structures\n","workspace_df = bronze_df.select(explode(\"value\").alias(\"workspace\"))\n","exploded_df = workspace_df.select(\n","    \"workspace.*\",  # select all top-level workspace fields\n","    explode(\"workspace.datasets\").alias(\"dataset\")  # explode datasets\n",")\n","\n","# Handle field name collisions (e.g., 'id', 'name') and get top-level workspace fields\n","workspace_fields = [f.name for f in exploded_df.schema if f.name not in (\"dataset\", \"datasets\")]\n","\n","# Rename dataset fields with prefix if they conflict with workspace fields\n","dataset_fields = []\n","for field in exploded_df.schema[\"dataset\"].dataType.fields:\n","    field_name = field.name\n","    new_name = f\"dataset{field_name[0].upper()}{field_name[1:]}\" if field_name in workspace_fields else field_name\n","    dataset_fields.append(col(f\"dataset.{field_name}\").alias(new_name))\n","\n","# Extract json objects to tabular form\n","extracted_df = exploded_df.select(\n","    *[col(f) for f in workspace_fields],  # original workspace fields\n","    *dataset_fields                       # prefixed dataset fields\n",")\n","\n","# Convert key(s) to upper case\n","extracted_df = extracted_df.withColumn(\"id\", f.upper(f.col(\"id\")))\n","extracted_df = extracted_df.withColumn(\"capacityId\", f.upper(f.col(\"capacityId\")))\n","extracted_df = extracted_df.withColumn(\"datasetId\", f.upper(f.col(\"datasetId\")))\n","\n","# Generate empty description column in case it is not available\n","if  not (\"description\" in extracted_df.columns):\n","    print(\"Created an empty description column\")\n","    extracted_df = extracted_df.withColumn(\"w.description\", lit(\"\"))\n","\n","print(f\"Bronze data from {bronze_file_location} has been extracted and transformed.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"59be80f0-a309-4e83-9fc4-a7666be86bcb"},{"cell_type":"code","source":["if display_data:\n","    display(extracted_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"28498c7f-c717-45cb-a368-2b4c58184cba"},{"cell_type":"code","source":["# Select columns required for the silver layer table\n","silver_df = extracted_df.select(\n","    col(\"capacityId\").alias(\"CapacityId\"),\n","    col(\"id\").alias(\"WorkspaceId\"),\n","    col(\"description\").alias(\"WorkspaceDescription\"),\n","    col(\"hasWorkspaceLevelSettings \").alias(\"HasWorkspaceLevelSettings\"),\n","    col(\"isOnDedicatedCapacity\").alias(\"IsOnDedicatedCapacity\"),\n","    col(\"isReadOnly\").alias(\"IsReadOnly\"),\n","    col(\"name\").alias(\"WorkspaceName\"),\n","    col(\"state\").alias(\"State\"),\n","    col(\"type\").alias(\"Type\"),\n","    col(\"datasetId\").alias(\"DatasetId\"),\n","    col(\"datasetName\").alias(\"DatasetName\"),\n","    col(\"configuredBy\").alias(\"DatasetConfiguredBy\"),\n","    col(\"isRefreshable\").alias(\"IsDatasetRefreshable\"),\n","    col(\"createdDate\").alias(\"DatasetCreatedDate\")\n","    )\n","\n","print(f\"Silver layer table columns have been extracted successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9e65f00b-f052-4c71-8a0d-c7cf094e84a7"},{"cell_type":"code","source":["if display_data:\n","    display(silver_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"d04bb645-fa43-482a-b96f-292422d5ff63"},{"cell_type":"code","source":["# Write prepared bronze_df to silver delta table\n","silver_df.write.mode(\"append\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable(silver_table_name)\n","\n","print(f\"Silver layer table {silver_table_name} has been created successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"74d9a7a3-cd0b-417d-987a-9ba70c3bb108"},{"cell_type":"code","source":["\n","# This function maps and merges the silver data to gold dynamically\n","def write_silver_to_gold(silver_table_name, gold_table_name, ids):\n","    query = \"SELECT *, current_timestamp() AS fuam_modified_at, False as fuam_deleted  FROM \" + silver_table_name \n","    silver_df = spark.sql(query)\n","    \n","    if spark.catalog.tableExists(gold_table_name):\n","        # if exists -> MERGE to gold\n","        print(\"Gold table exists and will be merged.\")\n","        gold_df = DeltaTable.forName(spark, gold_table_name)\n","\n","\n","        gold_columns = gold_df.toDF().columns\n","        silver_columns = silver_df.columns\n","        combined_columns = list(set(gold_columns) | set(silver_columns))\n","        id_cols = {}\n","        merge_id_stmt = ''\n","        for col in combined_columns:\n","            if col in ids:\n","                merge_id_stmt =  merge_id_stmt +  \" t.\" + col + \" = s.\" + col + \" and\"\n","                id_cols[col] = \"s.\" + col\n","\n","                \n","        # delete last and in merge id statement\n","        merge_id_stmt = merge_id_stmt[:-4]\n","\n","\n","        # Merge silver (s = source) to gold (t = target)\n","        try:\n","            merge = (gold_df.alias('t') \\\n","            .merge(silver_df.alias('s'), merge_id_stmt )) \\\n","            .whenMatchedUpdateAll() \\\n","            .whenNotMatchedInsertAll() \\\n","            .whenNotMatchedBySourceUpdate( condition = \"t.fuam_deleted == False or t.fuam_deleted IS NULL\", set = {\"fuam_deleted\" : \"True\", \"fuam_modified_at\": \"current_timestamp()\"} )\n","            \n","            merge.execute()\n","        except:\n","        # In case the tables already exist, but the fuam column are not existent because of an old version do merge whenNotMatchedBySourceUpdate\n","            merge = (gold_df.alias('t') \\\n","            .merge(silver_df.alias('s'), merge_id_stmt )) \\\n","            .whenMatchedUpdateAll() \\\n","            .whenNotMatchedInsertAll() \\\n","                        \n","            merge.execute()\n","\n","    else:\n","        # else -> INSERT to gold\n","        print(\"Gold table will be created.\")\n","\n","        silver_df.write.mode(\"append\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable(gold_table_name)\n","\n","print(\"The function 'write_silver_to_gold' has been created successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"581c54c3-0afd-493d-b6d0-14bd415b4158"},{"cell_type":"code","source":["# Merge semantic model refreshes to gold table\n","write_silver_to_gold(silver_table_name, gold_table_name, ['WorkspaceId', 'DatasetId'])\n","\n","print(f\"Gold layer table {gold_table_name} has been created successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2cf057a6-822c-44c9-9ceb-e66f2b8859c3"},{"cell_type":"code","source":["# Write history of bronze files\n","history_file_location = bronze_file_location.replace(\"Files/raw/\", \"Files/history/\") + datetime.datetime.now().strftime('%Y/%m/%d') + \"/\"\n","\n","files = mssparkutils.fs.ls(bronze_file_location) # type: ignore\n","for file in files:\n","    if not file.isDir:  # skip subdirectories, just in case\n","        dest_path = history_file_location + file.name\n","        mssparkutils.fs.cp(file.path, dest_path, True) # type: ignore\n","\n","print(f\"Bronze layer raw files have been copied successfully to {history_file_location}.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"375e3168-aa62-4abc-b2ee-09f41a2b8f3f"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"a365ComputeOptions":null,"sessionKeepAliveTimeout":0,"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"a2655017-a58a-416b-b08c-c9fbbf6a8ac7"},{"id":"18b54cf0-d96b-4e20-8080-30b42749b2c0"}],"default_lakehouse":"a2655017-a58a-416b-b08c-c9fbbf6a8ac7","default_lakehouse_name":"FUAM_Ext_Lakehouse","default_lakehouse_workspace_id":"572c83e2-ec60-4579-9648-10234b4a30d1"},"environment":{}}},"nbformat":4,"nbformat_minor":5}