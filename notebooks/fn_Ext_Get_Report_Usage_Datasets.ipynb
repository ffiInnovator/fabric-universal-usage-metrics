{"cells":[{"cell_type":"markdown","source":["#### Report Usage Datasets \n","\n","##### Data ingestion strategy:\n","<mark style=\"background: #88D5FF;\">**N/A**</mark>\n","\n","##### Related pipeline:\n","\n","**Ext_Load_PBI_Report_Usage_E2E**\n","\n","##### Source:\n","\n","**Table** from FUAM_Ext_Lakehouse table **gold_table_name** variable\n","\n","##### Target:\n","\n","**1 Data pipeline** in related_pipeline \n","- **odata_response_json** variable value returned by notebook"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a3f9a26c-41cc-4b72-a3af-b7ab0a82c453"},{"cell_type":"code","source":["import json\n","from pyspark.sql import SparkSession\n","from notebookutils import mssparkutils # type: ignore\n","\n","print(\"Successfully imported all packages for this notebook.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"07036bd2-4d58-42d5-b2c7-464373b57fa8"},{"cell_type":"code","source":["#\n","# Create the Spark session\n","#\n","app_name = \"GetReportUsageDatasets\"\n","\n","# Get the current Spark session\n","spark = SparkSession.builder \\\n","    .appName(app_name) \\\n","    .getOrCreate()\n","\n","print(f\"Spark session {app_name} has been created successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"45921d64-455f-417b-9ea6-0103fcc3ab52"},{"cell_type":"code","source":["## Parameters\n","display_data = True\n","\n","## Variables\n","gold_table_name = \"workspace_datasets\"\n","\n","print(\"Successfully configured all paramaters for this run.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c6b1b2d1-d106-4d47-927e-e1f864194584"},{"cell_type":"code","source":["# Read from the Lakehouse table\n","df = spark.read.table(gold_table_name)\n","\n","# Filter by DatasetName\n","# filtered_df = df.filter(df[\"DatasetName\"] == \"Report Usage Metrics Model\") # Old usage report format\n","filtered_df = df.filter(df[\"DatasetName\"] == \"Usage Metrics Report\") # New usage report format\n","\n","# Select only needed columns\n","selected_df = filtered_df.select(\"WorkspaceId\", \"DatasetId\")\n","\n","print(f\"Gold layer table {gold_table_name} has been read and filtered successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"60801cc8-2ee7-4553-a2d0-a66d1a71be41"},{"cell_type":"code","source":["if display_data:\n","    display(selected_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"f14cfbd3-73ba-41aa-80fa-a4e156f03dbe"},{"cell_type":"code","source":["# Collect the values to a list of dicts\n","results = selected_df.rdd.map(lambda row: {\"WorkspaceId\": row[\"WorkspaceId\"], \"DatasetId\": row[\"DatasetId\"]}).collect()\n","\n","# Wrap the results in the desired format\n","odata_response = {\n","    \"@odata.context\": \"https://wabi-us-east2-d-primary-redirect.analysis.windows.net/v1.0/myorg/admin/$metadata#groups\",\n","    \"@odata.count\": len(results),\n","    \"value\": results\n","}\n","\n","# Convert the response to a JSON string\n","odata_response_json = json.dumps(odata_response)\n","if display_data:\n","   print(odata_response_json)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5552beab-13bb-40bd-81d9-7ba6af16d5fa"},{"cell_type":"code","source":["type(odata_response_json)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1128e9eb-0d0f-492f-a24b-b1e9d816e5fe"},{"cell_type":"code","source":["print(\"Successfully created the result JSON which will be returned to the pipeline.\")\n","\n","# Send result to pipeline variable\n","mssparkutils.notebook.exit(odata_response_json)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"93b4a144-f132-4839-b31d-183ff5a851d4"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"a2655017-a58a-416b-b08c-c9fbbf6a8ac7"}],"default_lakehouse":"a2655017-a58a-416b-b08c-c9fbbf6a8ac7","default_lakehouse_name":"FUAM_Ext_Lakehouse","default_lakehouse_workspace_id":"572c83e2-ec60-4579-9648-10234b4a30d1"}}},"nbformat":4,"nbformat_minor":5}