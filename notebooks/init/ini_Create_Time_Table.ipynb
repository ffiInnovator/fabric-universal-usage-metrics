{"cells":[{"cell_type":"code","source":["## Parameters\n","display_data = True\n","table_name = \"time\"\n","\n","print(\"Successfully configured all paramaters for this run.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"63d92589-b380-4a17-bc74-764d8e978298"},{"cell_type":"code","source":["## Import all packages used in this notebook\n","from pyspark.sql import SparkSession, Row\n","from pyspark.sql.functions import col, when, expr, date_format, hour, minute\n","from datetime import datetime, timedelta, time\n","\n","print(\"Successfully imported all packages for this notebook.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9103bfef-31ef-44e7-93a7-cd6d2eb8f8fc"},{"cell_type":"code","source":["#\n","# Create the Spark session\n","#\n","app_name = \"TimeDimensionBuilder\"\n","\n","# Get the current Spark session\n","spark = SparkSession.builder \\\n","    .appName(app_name) \\\n","    .getOrCreate()\n","\n","print(f\"Spark session {app_name} has been created successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8c769fd3-5ef5-48c3-ad91-a489e353cda5"},{"cell_type":"code","source":["# ðŸ§© Step 1: Create the Day Period Lookup Table\n","\n","# Define day periods with start and end times\n","periods = [\n","    (\"00:00:00\", \"05:59:00\", \"Early Morning\"),\n","    (\"06:00:00\", \"11:59:00\", \"Morning\"),\n","    (\"12:00:00\", \"17:59:00\", \"Afternoon\"),\n","    (\"18:00:00\", \"20:59:00\", \"Evening\"),\n","    (\"21:00:00\", \"23:59:00\", \"Night\")\n","]\n","\n","base_date = datetime(2000, 1, 1)\n","records = []\n","\n","for start, end, label in periods:\n","    start_dt = datetime.strptime(f\"{base_date.date()} {start}\", \"%Y-%m-%d %H:%M:%S\")\n","    end_dt = datetime.strptime(f\"{base_date.date()} {end}\", \"%Y-%m-%d %H:%M:%S\")\n","    for i in range(int((end_dt - start_dt).total_seconds() // 60) + 1):\n","        ts = start_dt + timedelta(minutes=i)\n","        records.append(Row(\n","            DayPeriodStart=start_dt,\n","            DayPeriodEnd=end_dt,\n","            DayPeriod=label,\n","            MinuteKey=ts.strftime(\"%H:%M\")\n","        ))\n","\n","day_period_df = spark.createDataFrame(records)\n","\n","\n","print(\"Successfully created the day period dataframe.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fe99de8f-4a44-4ef8-9da8-c7d2857cbd79"},{"cell_type":"code","source":["if display_data:\n","    display(day_period_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"793f7bbf-94c6-4c66-aaa3-8a1f999d2efd"},{"cell_type":"code","source":["# ðŸ§© Step 2: Build the Time Dimension at Minute Grain\n","\n","# Create one row for every second of the day\n","base_datetime = datetime(2000, 1, 1)\n","rows = [Row(Time=base_datetime + timedelta(seconds=i)) for i in range(86400)]\n","time_df = spark.createDataFrame(rows)\n","\n","# Derive minute-level columns\n","minute_df = time_df \\\n","    .withColumn(\"HourNumber\", hour(\"Time\")) \\\n","    .withColumn(\"MinuteNumber\", minute(\"Time\")) \\\n","    .withColumn(\"Hour\", expr(\"make_timestamp(2000, 1, 1, HourNumber, 0, 0)\")) \\\n","    .withColumn(\"Minute\", expr(\"make_timestamp(2000, 1, 1, HourNumber, MinuteNumber, 0)\")) \\\n","    .withColumn(\"QuarterHour\", expr(\"\"\"\n","        CASE \n","            WHEN MinuteNumber < 15 THEN make_timestamp(2000,1,1,HourNumber,0,0)\n","            WHEN MinuteNumber < 30 THEN make_timestamp(2000,1,1,HourNumber,15,0)\n","            WHEN MinuteNumber < 45 THEN make_timestamp(2000,1,1,HourNumber,30,0)\n","            ELSE make_timestamp(2000,1,1,HourNumber,45,0)\n","        END\n","    \"\"\")) \\\n","    .withColumn(\"HalfHour\", expr(\"\"\"\n","        CASE \n","            WHEN MinuteNumber < 30 THEN make_timestamp(2000,1,1,HourNumber,0,0)\n","            ELSE make_timestamp(2000,1,1,HourNumber,30,0)\n","        END\n","    \"\"\")) \\\n","    .withColumn(\"TimeId\", date_format(\"Time\", \"HHmm\").cast(\"int\")) \\\n","    .withColumn(\"MinuteKey\", date_format(\"Time\", \"HH:mm\")) \\\n","    .dropDuplicates([\"TimeId\"]) \\\n","    .select(\n","        \"TimeId\",\n","        \"MinuteNumber\",\n","        \"Minute\",\n","        \"QuarterHour\",\n","        \"HalfHour\",\n","        \"HourNumber\",\n","        \"Hour\",\n","        \"MinuteKey\"\n","    )\n","\n","\n","print(\"Successfully created the minute-grain dataframe.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1b8ae40e-7cbd-4659-a20d-d0ef28c48781"},{"cell_type":"code","source":["if display_data:\n","    display(minute_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"62560521-509f-46cc-9ec8-e404c1f20ed0"},{"cell_type":"code","source":["# ðŸ§© Step 3: Join Day Period to Time Table\n","\n","# Add join key to day_period_df\n","day_period_df = day_period_df.withColumn(\"MinuteKey\", col(\"MinuteKey\"))\n","\n","# Join and enrich\n","final_df = minute_df.join(day_period_df, on=\"MinuteKey\", how=\"left\").drop(\"MinuteKey\")\n","\n","# Add AM/PM and business hour flags\n","final_df = final_df \\\n","    .withColumn(\"IsAM\", when(hour(\"Minute\") < 12, True).otherwise(False)) \\\n","    .withColumn(\"IsBusinessHour\", when((hour(\"Minute\") >= 9) & (hour(\"Minute\") <= 17), True).otherwise(False))\n","\n","\n","print(\"Successfully created the final time dataframe by joining the day-period and minute-grained.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6b64f799-787a-4e1a-b5c4-dbc492f3e831"},{"cell_type":"code","source":["if display_data:\n","    display(final_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"e4014036-0919-4d40-9132-32406b2021c1"},{"cell_type":"code","source":["# ðŸ§© Step 4: Save to Microsoft Fabric Lakehouse\n","final_df.write \\\n","    .format(\"delta\") \\\n","    .mode(\"overwrite\") \\\n","    .saveAsTable(table_name)\n","\n","\n","print(f\"Successfully created the table {table_name} in the lakehouse with {final_df.count()} rows.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a1f65b3e-8507-4af5-8e05-b418d6da06d1"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"a2655017-a58a-416b-b08c-c9fbbf6a8ac7"}],"default_lakehouse":"a2655017-a58a-416b-b08c-c9fbbf6a8ac7","default_lakehouse_name":"FUAM_Ext_Lakehouse","default_lakehouse_workspace_id":"572c83e2-ec60-4579-9648-10234b4a30d1"}}},"nbformat":4,"nbformat_minor":5}