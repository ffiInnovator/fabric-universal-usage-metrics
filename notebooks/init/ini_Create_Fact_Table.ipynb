{"cells":[{"cell_type":"code","source":["## Parameters\n","display_data = True\n","\n","usage_table_name = \"Report views\"\n","bronze_file_location = \"Files/raw/report_usage/facts/report_views/\"\n","gold_table_name = \"report_views\"\n","usage_dataset_id = \"28678a20-198b-4fa5-8cb2-d211f273af85\"\n","\n","print(\"Successfully configured all paramaters for this run.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"d9a33d27-0cb3-4fce-88ac-0c112ce659bd"},{"cell_type":"code","source":["## Import all packages used in this notebook\n","import datetime\n","from pyspark.sql.functions import col, explode, to_date, date_format, lit, upper # type: ignore\n","import pyspark.sql.functions as f # type: ignore\n","from pyspark.sql import SparkSession # type: ignore\n","import re\n","import time\n","\n","print(\"Successfully imported all packages for this notebook.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"10a066cc-e3ea-4049-8c46-e35cc24596a0"},{"cell_type":"code","source":["#\n","# Create the Spark session\n","#\n","app_name = \"CreateFactTable\"\n","\n","# Get the current Spark session\n","spark = SparkSession.builder \\\n","    .appName(app_name) \\\n","    .getOrCreate()\n","\n","print(f\"Spark session {app_name} has been created successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b2cc01fe-7549-473b-88c8-2f438291131c"},{"cell_type":"code","source":["#\n","# Function to get check if the gold layer table already exists\n","#\n","def gold_table_exists(gold_table_name: str, spark) -> bool:\n","    \"\"\"\n","    Checks if a table exists in the FUAM_Ext_Lakehouse catalog.\n","\n","    Args:\n","        gold_table_name (str): Name of the table to check.\n","        spark (SparkSession): The active Spark session.\n","\n","    Returns:\n","        bool: True if the table exists, False otherwise.\n","    \"\"\"\n","    table_exists = spark._jsparkSession.catalog().tableExists('FUAM_Ext_Lakehouse', gold_table_name)\n","    return table_exists\n","\n","print(\"The function 'gold_table_exists' has been created successfully.\") "],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fe71ddf4-7352-4354-9dec-5b8a9df536be"},{"cell_type":"code","source":["#\n","# Get the report usage data from the BRONZE layer\n","# Read the JSON files using 'multiline' since it's pretty-printed\n","#\n","raw_location = f\"{bronze_file_location}{usage_dataset_id.upper()}.json\"\n","bronze_df = spark.read.option(\"multiline\", \"true\").json(raw_location)\n","\n","print(f\"Bronze data from {raw_location} has been read successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e2d4ffc0-87b9-4f22-8ed0-4ca37e26e46f"},{"cell_type":"code","source":["if display_data:\n","    display(bronze_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"0aee684d-32a3-4072-b0f3-7787d62399ac"},{"cell_type":"code","source":["#\n","# Explode results -> tables -> rows\n","#\n","exploded_results = bronze_df.select(explode(\"results\").alias(\"result\"))\n","exploded_tables = exploded_results.select(explode(\"result.tables\").alias(\"table\"))\n","exploded_rows = exploded_tables.select(explode(\"table.rows\").alias(\"row\"))\n","\n","print(f\"Bronze data from {raw_location} has been extracted and transformed.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"416f1a4a-b9a6-491f-a553-2b8235f229d7"},{"cell_type":"code","source":["if display_data:\n","    display(exploded_rows)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"7cf4f0bd-d3d9-4d37-91f8-aec973979535"},{"cell_type":"code","source":["#\n","# Create the silver layer dataframe\n","# Dataset IDs in the Lakehouse are expected to be uppercase\n","#\n","usage_dataset_id = usage_dataset_id.upper()\n","\n","# Create the silver dataframe\n","silver_df = exploded_rows.select(\n","    lit(usage_dataset_id).alias(\"UsageDatasetId\"), # Add to enable the append processing logic\n","    col(\"row.*\")\n",")\n","\n","# Rename columns with brackets to just the inner name\n","for col_name in silver_df.columns:\n","    match = re.search(r\"\\[(.*?)\\]\", col_name)\n","    if match:\n","        new_col_name = match.group(1)\n","        silver_df = silver_df.withColumnRenamed(col_name, new_col_name)\n","\n","# Put selected ID columns to Upper Case\n","for co in silver_df.columns:\n","    if co in ['CapacityId','WorkspaceId', 'ReportId']:\n","        silver_df = silver_df.withColumn(co, f.upper(silver_df[co]))\n","\n","# Transformation to standardize the time column\n","if \"Timestamp\" in silver_df.columns and \"CreationTime\" not in silver_df.columns:\n","    silver_df = silver_df.withColumnRenamed(\"Timestamp\", \"CreationTime\")\n","\n","# Transform the time stamp string data field\n","silver_df = silver_df.withColumn(\"CreationDate\", to_date(col(\"CreationTime\").substr(1, 10), \"yyyy-MM-dd\")) \\\n","                    .withColumn(\"CreationDateKey\", date_format(col(\"CreationTime\"), \"yyyyMMdd\")) \\\n","                    .withColumn(\"CreationHour\", date_format(col(\"CreationTime\"), \"H\")) \\\n","                    .withColumn(\"CreationMinute\", date_format(col(\"CreationTime\"), \"mm\"))\n","\n","print(f\"Silver dataframe has been created successfully with {silver_df.count()} rows.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0b17bb5c-3388-4dfe-8285-85b0a49089db"},{"cell_type":"code","source":["if display_data:\n","    display(silver_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"6b963ac5-d071-4ab8-bb3d-34704ff45cb5"},{"cell_type":"code","source":["#\n","# Write silver_df as a partitioned Delta table in Fabric lakehouse\n","#\n","silver_df.write \\\n","    .format(\"delta\") \\\n","    .partitionBy(\"UsageDatasetId\", \"ReportId\") \\\n","    .mode(\"errorifexists\") \\\n","    .saveAsTable(gold_table_name)\n","\n","print(f\"Gold table {gold_table_name} has been created successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"78c430fc-6e88-4085-9297-b0988ffdb60e"},{"cell_type":"code","source":["#\n","# Write history of bronze files\n","#\n","raw_path = bronze_file_location.replace(\"*/\", '', )\n","history_path = raw_path.replace(\"Files/raw/\", \"Files/history/\")\n","mssparkutils.fs.cp(raw_path, history_path + datetime.datetime.now().strftime('%Y/%m/%d') + \"/\", True) # type: ignore\n","\n","print(f\"History data copied to {history_path} successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f7a1e9a8-7730-4d1f-b028-4d16df5b9117"},{"cell_type":"code","source":["#\n","# Stop the Spark session\n","# NOTE: frees up limited F2 SKU capacity resources\n","#\n","spark.stop()\n","\n","print(\"Spark session has been stopped successfully.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d8781635-aab8-4bd4-b2b1-9a3519ec65bc"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"a365ComputeOptions":null,"sessionKeepAliveTimeout":0,"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"a2655017-a58a-416b-b08c-c9fbbf6a8ac7"}],"default_lakehouse":"a2655017-a58a-416b-b08c-c9fbbf6a8ac7","default_lakehouse_name":"FUAM_Ext_Lakehouse","default_lakehouse_workspace_id":"572c83e2-ec60-4579-9648-10234b4a30d1"},"environment":{}}},"nbformat":4,"nbformat_minor":5}